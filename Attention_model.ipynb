{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "mvFxCWhGRE0e",
    "outputId": "8d43c516-8e86-4401-84e6-66650d6c921c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "rAqXmMOrX5WA",
    "outputId": "9f39b70a-9ad3-414f-9ed7-6c7438940784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 14)\n",
      "(202, 128, 128, 1)\n",
      "(191027, 14)\n",
      "(30000, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "import bz2, pickle\n",
    "\n",
    "with bz2.BZ2File('/content/drive/My Drive/Colab Notebooks/test_label_128.pbz2','r') as f:\n",
    "    test_label = pickle.load(f)\n",
    "with bz2.BZ2File('/content/drive/My Drive/Colab Notebooks/train_label_128.pbz2','r') as f:\n",
    "    train_label = pickle.load(f)\n",
    "with bz2.BZ2File('/content/drive/My Drive/Colab Notebooks/test_data_128.pbz2','r') as f:\n",
    "    test_data = pickle.load(f)\n",
    "with bz2.BZ2File('/content/drive/My Drive/Colab Notebooks/train_data_1_128.pbz2','r') as f:\n",
    "    train_data1 = pickle.load(f)\n",
    "    \n",
    "print(test_label.shape)\n",
    "print(test_data.shape)\n",
    "print(train_label.shape)\n",
    "print(train_data1.shape)\n",
    "#print(train_data2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "WrBpspjiRkuT",
    "outputId": "2df6a18a-7d5c-445e-ea45-f2b6f6f2c40d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.densenet import *\n",
    "from keras.applications.vgg16 import *\n",
    "from keras.optimizers import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Model, load_model\n",
    "from keras.activations import *\n",
    "\n",
    "import keras, tensorflow as tf, keras.backend as K, numpy as np, cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-RcFjU0xReGg",
    "outputId": "5b5071b5-cc58-493a-9d69-51c7d9ec699a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   (None, 4, 4, 512)    14713536    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 4, 4, 512)    2048        vgg16[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 4, 4, 64)     32832       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 16)     1040        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "locally_connected2d_1 (LocallyC (None, 4, 4, 1)      272         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 512)    512         locally_connected2d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 4, 4, 512)    0           conv2d_3[0][0]                   \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 512)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 512)          0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "RescaleGAP (Lambda)             (None, 512)          0           global_average_pooling2d_1[0][0] \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           RescaleGAP[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 14)           3598        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,885,166\n",
      "Trainable params: 170,094\n",
      "Non-trainable params: 14,715,072\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_pretrained_model = VGG16(weights=None,include_top=False, input_shape=(128,128,1))\n",
    "base_pretrained_model.trainable = False\n",
    "in_lay = Input((128,128,1))\n",
    "pt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\n",
    "pt_features = base_pretrained_model(in_lay)\n",
    "bn_features = BatchNormalization()(pt_features)\n",
    "\n",
    "# here we do an attention mechanism to turn pixels in the GAP on an off\n",
    "\n",
    "attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(bn_features)\n",
    "attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "attn_layer = LocallyConnected2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n",
    "# fan it out to all of the channels\n",
    "up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', activation = 'linear', use_bias = False, weights = [up_c2_w])\n",
    "up_c2.trainable = False\n",
    "attn_layer = up_c2(attn_layer)\n",
    "\n",
    "mask_features = multiply([attn_layer, bn_features])\n",
    "gap_features = GlobalAveragePooling2D()(mask_features)\n",
    "gap_mask = GlobalAveragePooling2D()(attn_layer)\n",
    "# to account for missing values from the attention model\n",
    "gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "gap_dr = Dropout(0.5)(gap)\n",
    "dr_steps = Dropout(0.25)(Dense(256, activation = 'relu')(gap_dr))\n",
    "out_layer = Dense(14, activation = 'sigmoid')(dr_steps) # linear is what 16bit did\n",
    "att_model = Model(inputs = [in_lay], outputs = [out_layer])\n",
    "\n",
    "att_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "att_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649
    },
    "colab_type": "code",
    "id": "X2cDpmvTRj1R",
    "outputId": "d161cbfb-eda0-4910-f78f-67b551a6d2e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/15\n",
      "20000/20000 [==============================] - 30s 1ms/step - loss: 0.3784 - acc: 0.8346 - val_loss: 0.3576 - val_acc: 0.8435\n",
      "Epoch 2/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3566 - acc: 0.8402 - val_loss: 0.3508 - val_acc: 0.8447\n",
      "Epoch 3/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3484 - acc: 0.8471 - val_loss: 0.3458 - val_acc: 0.8490\n",
      "Epoch 4/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3458 - acc: 0.8492 - val_loss: 0.3455 - val_acc: 0.8498\n",
      "Epoch 5/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3441 - acc: 0.8506 - val_loss: 0.3434 - val_acc: 0.8498\n",
      "Epoch 6/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3432 - acc: 0.8512 - val_loss: 0.3424 - val_acc: 0.8506\n",
      "Epoch 7/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3422 - acc: 0.8512 - val_loss: 0.3417 - val_acc: 0.8507\n",
      "Epoch 8/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3409 - acc: 0.8517 - val_loss: 0.3406 - val_acc: 0.8515\n",
      "Epoch 9/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3395 - acc: 0.8524 - val_loss: 0.3398 - val_acc: 0.8516\n",
      "Epoch 10/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3389 - acc: 0.8524 - val_loss: 0.3402 - val_acc: 0.8513\n",
      "Epoch 11/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3385 - acc: 0.8528 - val_loss: 0.3392 - val_acc: 0.8506\n",
      "Epoch 12/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3372 - acc: 0.8535 - val_loss: 0.3371 - val_acc: 0.8530\n",
      "Epoch 13/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3368 - acc: 0.8534 - val_loss: 0.3374 - val_acc: 0.8529\n",
      "Epoch 14/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3361 - acc: 0.8538 - val_loss: 0.3358 - val_acc: 0.8531\n",
      "Epoch 15/15\n",
      "20000/20000 [==============================] - 24s 1ms/step - loss: 0.3360 - acc: 0.8539 - val_loss: 0.3354 - val_acc: 0.8531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd279dbd080>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_model.fit(train_data1[:20000], train_label[:20000], validation_data = (train_data1[20000:25000], train_label[20000:25000]), epochs=15, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wafxxtItdQCr"
   },
   "source": [
    "## Testing Attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "aI6jWRTzYnxF",
    "outputId": "a6993d55-7fa5-4619-81be-8f018a74735f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 5s 1ms/step\n",
      "Test Accuracy = 85.24714132308961 %\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accu = att_model.evaluate(train_data1[25000:30000,], train_label[25000:30000,])\n",
    "print('Test Accuracy =', test_accu*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Attention model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
